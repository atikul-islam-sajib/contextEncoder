{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def dump(value=None, filename=None):\n",
    "    if (value is not None) and (filename is not None):\n",
    "        joblib.dump(value=value, filename=filename)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"value and filename must be provided\".capitalize())\n",
    "\n",
    "\n",
    "def load(filename=None):\n",
    "    if filename is not None:\n",
    "        return joblib.load(filename=filename)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"filename should be defined\".capitalize())\n",
    "\n",
    "\n",
    "def device_init(device=\"cuda\"):\n",
    "    if device == \"cuda\":\n",
    "        return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    elif device == \"mps\":\n",
    "        return torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "def weight_init(m):\n",
    "    classname = m.__class__\n",
    "\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "def config():\n",
    "    with open(\"./config.yml\", \"r\") as file:\n",
    "        return yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels = 3, out_channels = 64, kernel_size = 4, stride = 2, padding = 1, use_norm = True):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.is_normalization = use_norm\n",
    "        \n",
    "        self.encoder_block = self.block()\n",
    "        \n",
    "    def block(self):\n",
    "        self.layers = []\n",
    "        \n",
    "        self.layers.append(\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.in_channels,\n",
    "                out_channels=self.out_channels,\n",
    "                kernel_size=self.kernel_size,\n",
    "                stride=self.stride,\n",
    "                padding=self.padding\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        if self.is_normalization:\n",
    "            self.layers.append(nn.BatchNorm2d(num_features=self.out_channels))\n",
    "            \n",
    "        self.layers.append(nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
    "        \n",
    "        return nn.Sequential(*self.layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return self.encoder_block(x)\n",
    "        else:\n",
    "            raise ValueError(\"Input should be in the format of the tensor\".capitalize())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    in_channels = 3\n",
    "    out_channels = 64\n",
    "    kernel_size = 4\n",
    "    stride = 2\n",
    "    padding = 1\n",
    "\n",
    "    layers = []\n",
    "\n",
    "    for _ in range(2):\n",
    "        layers.append(EncoderBlock(\n",
    "            in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, use_norm=False))\n",
    "\n",
    "        in_channels = out_channels\n",
    "\n",
    "    for _ in range(3):\n",
    "        layers.append(EncoderBlock(\n",
    "            in_channels=in_channels, out_channels=out_channels * 2, kernel_size=kernel_size, stride=stride, padding=padding, use_norm=True))\n",
    "\n",
    "        in_channels = out_channels * 2\n",
    "        out_channels = in_channels\n",
    "\n",
    "    layers.append(\n",
    "        nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=4000,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0\n",
    "        )\n",
    "    ) \n",
    "\n",
    "    model = nn.Sequential(*layers)\n",
    "\n",
    "    assert model(torch.randn(1, 3, 128, 128)).size() == (1, 4000, 4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels=4000, out_channels=512, kernel_size=4, stride=2, padding=1\n",
    "    ):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "        self.decoder_block = self.block()\n",
    "\n",
    "    def block(self):\n",
    "        self.layers = []\n",
    "\n",
    "        self.layers.append(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=self.in_channels,\n",
    "                out_channels=self.out_channels,\n",
    "                kernel_size=self.kernel_size,\n",
    "                stride=self.stride,\n",
    "                padding=self.padding,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.layers.append(nn.BatchNorm2d(num_features=self.out_channels))\n",
    "        self.layers.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        return nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return self.decoder_block(x)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Input should be in the format of the tensor\".capitalize())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    layers = []\n",
    "\n",
    "    in_channels = 4000\n",
    "    out_channels = 512\n",
    "    kernel_size = 4\n",
    "    stride = 2\n",
    "    padding = 1\n",
    "\n",
    "    for _ in range(4):\n",
    "        layers.append(\n",
    "            DecoderBlock(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "            )\n",
    "        )\n",
    "        in_channels = out_channels\n",
    "        out_channels = in_channels // 2\n",
    "\n",
    "    layers.append(\n",
    "        nn.ConvTranspose2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=3,\n",
    "            kernel_size=kernel_size - 1,\n",
    "            stride=stride // stride,\n",
    "            padding=padding,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model = nn.Sequential(*layers)\n",
    "\n",
    "    print(model(torch.randn(1, 4000, 4, 4)).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=64):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.kernel_size = 4\n",
    "        self.stride = 2\n",
    "        self.padding = 1\n",
    "\n",
    "        self.layers = []\n",
    "\n",
    "        for _ in range(2):\n",
    "            self.layers.append(\n",
    "                EncoderBlock(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=self.kernel_size,\n",
    "                    stride=self.stride,\n",
    "                    padding=self.padding,\n",
    "                    use_norm=False,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            in_channels = out_channels\n",
    "\n",
    "        for _ in range(3):\n",
    "            self.layers.append(\n",
    "                EncoderBlock(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels * 2,\n",
    "                    kernel_size=self.kernel_size,\n",
    "                    stride=self.stride,\n",
    "                    padding=self.padding,\n",
    "                    use_norm=True,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            in_channels = out_channels * 2\n",
    "            out_channels = in_channels\n",
    "\n",
    "        self.layers.append(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=4000,\n",
    "                kernel_size=self.kernel_size // self.kernel_size,\n",
    "                stride=self.stride // self.stride,\n",
    "                padding=0,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        in_channels = 4000\n",
    "\n",
    "        for _ in range(4):\n",
    "            self.layers.append(\n",
    "                DecoderBlock(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=self.kernel_size,\n",
    "                    stride=self.stride,\n",
    "                    padding=self.padding,\n",
    "                )\n",
    "            )\n",
    "            in_channels = out_channels\n",
    "            out_channels = in_channels // 2\n",
    "\n",
    "        self.layers.append(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=3,\n",
    "                kernel_size=self.kernel_size - 1,\n",
    "                stride=self.stride // self.stride,\n",
    "                padding=self.padding,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.model = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return self.model(x)\n",
    "        else:\n",
    "            raise ValueError(\"Input should be in the format of the tensor\".capitalize())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    netG = Generator()\n",
    "\n",
    "    print(netG(torch.randn(1, 3, 128, 128)).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorBlock(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=3,\n",
    "        out_channels=64,\n",
    "        momentum=0.8,\n",
    "        use_normalization=True,\n",
    "        stride=2,\n",
    "    ):\n",
    "        super(DiscriminatorBlock, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.kernel_size = 3\n",
    "        self.stride = stride\n",
    "        self.padding = 1\n",
    "        self.slope = 0.2\n",
    "\n",
    "        self.momentum = momentum\n",
    "\n",
    "        self.is_normalization = use_normalization\n",
    "\n",
    "        self.discriminator_block = self.block()\n",
    "\n",
    "    def block(self):\n",
    "        self.layers = []\n",
    "\n",
    "        self.layers.append(\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.in_channels,\n",
    "                out_channels=self.out_channels,\n",
    "                kernel_size=self.kernel_size,\n",
    "                stride=self.stride,\n",
    "                padding=self.padding,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if self.is_normalization:\n",
    "            self.layers.append(\n",
    "                nn.InstanceNorm2d(\n",
    "                    num_features=self.out_channels, momentum=self.momentum\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.layers.append(nn.LeakyReLU(negative_slope=self.slope, inplace=True))\n",
    "\n",
    "        self.model = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return self.model(x)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Input should be in the format of the tensor\".capitalize())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    layers = []\n",
    "\n",
    "    in_channels = 3\n",
    "    out_channels = 54\n",
    "    kernel_size = 3\n",
    "    stride = 2\n",
    "    padding = 1\n",
    "\n",
    "    for idx in range(4):\n",
    "        layers.append(\n",
    "            DiscriminatorBlock(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                stride=1 if (idx + 1) == 4 else 2,\n",
    "                use_normalization=False if idx == 0 else True,\n",
    "            )\n",
    "        )\n",
    "        in_channels = out_channels\n",
    "        out_channels *= 2\n",
    "\n",
    "    layers.append(\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=in_channels // in_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride // stride,\n",
    "                padding=padding,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model = nn.Sequential(*layers)\n",
    "\n",
    "    assert model(torch.randn(1, 3, 64, 64)).size() == (1, 1, 8, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        self.out_channels = 64\n",
    "        self.kernel_size = 3\n",
    "        self.stride = 2\n",
    "        self.padding = 1\n",
    "\n",
    "        self.layers = []\n",
    "\n",
    "        for idx in range(4):\n",
    "            self.layers.append(\n",
    "                DiscriminatorBlock(\n",
    "                    in_channels=self.in_channels,\n",
    "                    out_channels=self.out_channels,\n",
    "                    stride=1 if (idx + 1) == 4 else 2,\n",
    "                    use_normalization=False if idx == 0 else True,\n",
    "                )\n",
    "            )\n",
    "            self.in_channels = self.out_channels\n",
    "            self.out_channels *= 2\n",
    "\n",
    "        self.layers.append(\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=self.in_channels,\n",
    "                    out_channels=self.in_channels // self.in_channels,\n",
    "                    kernel_size=self.kernel_size,\n",
    "                    stride=self.stride // self.stride,\n",
    "                    padding=self.padding,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.model = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return self.model(x)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Input should be in the format of the tensor\".capitalize())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    netD = Discriminator()\n",
    "\n",
    "    print(netD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class AdversarialLoss(nn.Module):\n",
    "    def __init__(self, reduction=\"mean\"):\n",
    "        super(AdversarialLoss, self).__init__()\n",
    "\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, pred, actual):\n",
    "        if (isinstance(pred, torch.Tensor)) and (isinstance(actual, torch.Tensor)):\n",
    "            self.loss = nn.MSELoss(reduction=self.reduction)\n",
    "\n",
    "            return self.loss(predicted, actual)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Pred and actual should be in the tensor format\".capitalize()\n",
    "            )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    loss = AdversarialLoss()\n",
    "\n",
    "    predicted = torch.tensor([1.0, 0.0, 1.0, 0.0])\n",
    "    actual = torch.tensor([1.0, 0.0, 1.0, 0.0])\n",
    "\n",
    "    assert loss(predicted, actual) == (0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class PixelLoss(nn.Module):\n",
    "    def __init__(self, reduction=\"mean\"):\n",
    "        super(PixelLoss, self).__init__()\n",
    "\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, pred, actual):\n",
    "        if isinstance(pred, torch.Tensor) and isinstance(actual, torch.Tensor):\n",
    "            self.loss = nn.L1Loss(reduction=self.reduction)\n",
    "\n",
    "            return self.loss(pred, actual)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Pred and actual should be in the tensor format\".capitalize()\n",
    "            )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loss = PixelLoss()\n",
    "\n",
    "    predicted = torch.tensor([1.0, 0.0, 1.0, 0.0])\n",
    "    actual = torch.tensor([1.0, 0.0, 1.0, 0.0])\n",
    "\n",
    "    assert loss(predicted, actual) == (0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def helpers(**kwargs):\n",
    "    adam = kwargs[\"adam\"]\n",
    "    SGD = kwargs[\"SGD\"]\n",
    "    beta1 = kwargs[\"beta1\"]\n",
    "    beta2 = kwargs[\"beta2\"]\n",
    "    momentum = kwargs[\"momentum\"]\n",
    "    lr = kwargs[\"lr\"]\n",
    "\n",
    "    try:\n",
    "        netG = Generator(in_channels=3, out_channels=64)\n",
    "    except Exception as e:\n",
    "        print(\"An error is occured {}\".format(e))\n",
    "        traceback.print_exc()\n",
    "\n",
    "    try:\n",
    "        netD = Discriminator(in_channels=3)\n",
    "    except Exception as e:\n",
    "        print(\"An error is occured {}\".format(e))\n",
    "        traceback.print_exc()\n",
    "\n",
    "    if adam:\n",
    "        optimizerG = optim.Adam(params=netG.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "        optimizerD = optim.Adam(params=netD.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "\n",
    "    if SGD:\n",
    "        optimizerG = optim.SGD(params=netG.parameters(), lr=lr, momentum=momentum)\n",
    "        optimizerD = optim.SGD(params=netD.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    adversarial_loss = AdversarialLoss(reduction=\"mean\")\n",
    "    pixelwise_loss = PixelLoss(reduction=\"mean\")\n",
    "\n",
    "    return {\n",
    "        \"netG\": netG,\n",
    "        \"netD\": netD,\n",
    "        \"optimizerG\": optimizerG,\n",
    "        \"optimizerD\": optimizerD,\n",
    "        \"adversarial_loss\": adversarial_loss,\n",
    "        \"pixelwise_loss\": pixelwise_loss,\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    init = helpers(\n",
    "        adam=True, SGD=False, beta1=0.5, beta2=0.999, momentum=0.9, lr=0.0002\n",
    "    )\n",
    "\n",
    "    assert init[\"netG\"].__class__.__name__ == \"Generator\"\n",
    "    assert init[\"netD\"].__class__.__name__ == \"Discriminator\"\n",
    "\n",
    "    assert init[\"optimizerG\"].__class__.__name__ == \"Adam\"\n",
    "    assert init[\"optimizerD\"].__class__.__name__ == \"Adam\"\n",
    "\n",
    "    assert init[\"adversarial_loss\"].__class__.__name__ == \"AdversarialLoss\"\n",
    "    assert init[\"pixelwise_loss\"].__class__.__name__ == \"PixelLoss\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import unittest\n",
    "\n",
    "class UnitTest(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.encoder = EncoderBlock()\n",
    "        self.decoder = DecoderBlock()\n",
    "        self.netG = Generator()\n",
    "        self.netD = Discriminator()\n",
    "        self.init = helpers(\n",
    "            adam=True, SGD=False, beta1=0.5, beta2=0.999, momentum=0.9, lr=0.0002\n",
    "        )\n",
    "\n",
    "    def test_encoder_block(self):\n",
    "        in_channels = 3\n",
    "        out_channels = 64\n",
    "        kernel_size = 4\n",
    "        stride = 2\n",
    "        padding = 1\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        for _ in range(2):\n",
    "            layers.append(\n",
    "                EncoderBlock(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding=padding,\n",
    "                    use_norm=False,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            in_channels = out_channels\n",
    "\n",
    "        for _ in range(3):\n",
    "            layers.append(\n",
    "                EncoderBlock(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels * 2,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding=padding,\n",
    "                    use_norm=True,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            in_channels = out_channels * 2\n",
    "            out_channels = in_channels\n",
    "\n",
    "        layers.append(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=4000,\n",
    "                kernel_size=kernel_size // kernel_size,\n",
    "                stride=stride // stride,\n",
    "                padding=0,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        model = nn.Sequential(*layers)\n",
    "\n",
    "        self.assertEqual(\n",
    "            model(torch.randn(1, 3, 128, 128)).size(), torch.Size([1, 4000, 4, 4])\n",
    "        )\n",
    "\n",
    "    def test_decoder_block(self):\n",
    "        in_channels = 4000\n",
    "        out_channels = 512\n",
    "        kernel_size = 4\n",
    "        stride = 2\n",
    "        padding = 1\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        for _ in range(4):\n",
    "            layers.append(\n",
    "                DecoderBlock(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding=padding,\n",
    "                )\n",
    "            )\n",
    "            in_channels = out_channels\n",
    "            out_channels = in_channels // 2\n",
    "\n",
    "        layers.append(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=3,\n",
    "                kernel_size=kernel_size - 1,\n",
    "                stride=stride // stride,\n",
    "                padding=padding,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        model = nn.Sequential(*layers)\n",
    "\n",
    "        self.assertEqual(\n",
    "            model(torch.randn(1, 4000, 4, 4)).size(), torch.Size([1, 3, 64, 64])\n",
    "        )\n",
    "\n",
    "    def test_netG_size(self):\n",
    "        self.assertEqual(\n",
    "            self.netG(torch.randn(1, 3, 128, 128)).size(), torch.Size([1, 3, 64, 64])\n",
    "        )\n",
    "\n",
    "    def test_netD_size(self):\n",
    "        self.assertEqual(\n",
    "            self.netD(torch.randn(1, 3, 64, 64)).size(), torch.Size([1, 1, 8, 8])\n",
    "        )\n",
    "\n",
    "    def test_netG_total_params(self):\n",
    "        self.assertEqual(Generator.total_params(self.netG), 40401059)\n",
    "\n",
    "    def test_netD_total_params(self):\n",
    "        self.assertEqual(Discriminator.total_params(self.netD), 1555585)\n",
    "\n",
    "    def test_helpers(self):\n",
    "        self.assertIsInstance(self.init[\"netG\"], Generator)\n",
    "        self.assertIsInstance(self.init[\"netD\"], Discriminator)\n",
    "        self.assertIsInstance(self.init[\"optimizerG\"], optim.Adam)\n",
    "        self.assertIsInstance(self.init[\"optimizerD\"], optim.Adam)\n",
    "        self.assertIsInstance(self.init[\"adversarial_loss\"], AdversarialLoss)\n",
    "        self.assertIsInstance(self.init[\"pixelwise_loss\"], PixelLoss)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPSG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
